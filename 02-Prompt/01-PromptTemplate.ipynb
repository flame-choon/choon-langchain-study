{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LangSmith 추적을 시작합니다.\n",
      "[프로젝트명]\n",
      "02-Prompt\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_teddynote import logging\n",
    "\n",
    "# .env 파일 로드\n",
    "load_dotenv()\n",
    "\n",
    "# langSmith에 로깅 할 프로젝트 명을 입력\n",
    "logging.langsmith(\"02-Prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 객체 정의\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법 1. from_template() 메소드를 사용하여 PromptTemplate 객체 생성\n",
    "- 치환될 변수를 { 변수 }로 묶어서 템플릿을 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='한국의 수도는 서울입니다.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 8, 'prompt_tokens': 15, 'total_tokens': 23, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None} id='run-175984ee-b043-4210-86e4-babe8a377ff1-0' usage_metadata={'input_tokens': 15, 'output_tokens': 8, 'total_tokens': 23, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"country\": \"한국\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 방법 2. PromptTemplate 객체 생성과 동시에 Prompt 생성\n",
    "\n",
    "추가 유효성 검사를 위해 `input_variables`를 명시적으로 지정\n",
    "이러한 변수는 인스턴스화 중에 템플릿 문자열에 있는 변수와 비교하여 불일치 하는 경우 예외 발생"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='{country}의 수도는 어디인가요?')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# template 정의\n",
    "template = \"{country}의 수도는 어디인가요?\"\n",
    "\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"country\"])\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "방법 2보다는 방법 1이 더 편한 듯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### partial variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='캐나다의 수도는 오타와이고, 미국의 수도는 워싱턴 D.C.입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 18, 'total_tokens': 41, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_4691090a87', 'finish_reason': 'stop', 'logprobs': None}, id='run-ac22d9e3-83dd-409f-af37-1cffe5016433-0', usage_metadata={'input_tokens': 18, 'output_tokens': 23, 'total_tokens': 41, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = \"{country1} 과 {country2}의 수도는 각각 어디야?\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "prompt = prompt.partial(country1=\"캐나다\")\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "chain.invoke({\"country2\": \"미국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial을 이용하여 변수에 들어갈 기본 값을 정의 해줄수 있다. 혹은 부분 변수 채움이라 표현\n",
    "\n",
    "아래와 같이 기본 값이 정의 된 상태에서 invoke 시 새로운 변수 값을 할당해주면 Override 된다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='네덜란드의 수도는 암스테르담이고, 미국의 수도는 워싱턴 D.C.입니다.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 28, 'prompt_tokens': 21, 'total_tokens': 49, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-ff69435d-7eb3-42fa-8873-d16cd95e3241-0', usage_metadata={'input_tokens': 21, 'output_tokens': 28, 'total_tokens': 49, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"country1\": \"네덜란드\", \"country2\": \"미국\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "partial 을 좀 더 잘 활용해보고자 한다면 아래의 예처럼 오늘의 날짜를 미리 정의하는 방법이 있을 것이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# 오늘 날짜를 반환하는 함수 정의\n",
    "def get_today():\n",
    "    return datetime.now().strftime(\"%B %d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"오늘의 날짜는 {today} 입니다. 오늘이 생일 유명인 {n}명을 생년월일을 표기하여 나열해 주세요\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "prompt = prompt.partial(today=get_today())\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "February 3에 태어난 유명인 중 다섯 명은 다음과 같습니다:\n",
      "\n",
      "1. 노먼 록웰 (Norman Rockwell) - 1894년 2월 3일\n",
      "2. 모건 페어차일드 (Morgan Fairchild) - 1950년 2월 3일\n",
      "3. 네이선 레인 (Nathan Lane) - 1956년 2월 3일\n",
      "4. 이사벨라 스콜루프코 (Izabella Scorupco) - 1970년 2월 3일\n",
      "5. 워윅 데이비스 (Warwick Davis) - 1970년 2월 3일\n",
      "\n",
      "이들은 다양한 분야에서 활동한 유명인들입니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(5).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 파일로부터 template 읽어오기\n",
    "\n",
    "prompt를 작성하다 보면 짧은 것만 사용하는 것이 아니라 굉장히 긴 구조의 prompt를 생성하게 된다\n",
    "기존 처럼 template 변수에 정의 할때 긴 내용의 prompt를 직접 넣는 것이 아니라 yaml 파일에 정의해두면 간편하게 파일만 로드해서 사용할 수 있다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import load_prompt\n",
    "\n",
    "# load_prompt 메서드를 이용하여 yaml 파일을 로드\n",
    "prompt = load_prompt(\"prompts/capital.yaml\")\n",
    "prompt\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "미국의 수도는 워싱턴 D.C.입니다.\n",
      "\n",
      "1. 면적: 워싱턴 D.C.의 총 면적은 약 177제곱킬로미터입니다. 이는 상대적으로 작은 크기지만, 중요한 정치적 중심지로서 기능하고 있습니다.\n",
      "\n",
      "2. 인구: 2020년 기준으로 약 70만 명이 거주하고 있습니다. 다양한 배경을 가진 사람들이 모여 있으며, 정치와 행정 관련 인구가 많습니다.\n",
      "\n",
      "3. 역사적 장소: 워싱턴 D.C.에는 백악관, 미국 의회 의사당, 링컨 기념관, 그리고 워싱턴 기념비 등 미국의 역사와 정체성을 상징하는 많은 기념비와 박물관이 있습니다. 스미소니언 박물관과 같은 문화 기관도 유명합니다.\n",
      "\n",
      "4. 특산품: 워싱턴 D.C. 자체로는 전통적인 농산물 특산품은 없지만, 정치적 중심지로서 정치 관련 기념품과 출판물, 그리고 다양한 박물관에서 제공하는 문화상품이 특색 있는 상품으로 꼽힙니다.\n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke({\"country\": \"미국\"}).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatPromptTemplate\n",
    "\n",
    "`ChatPromptTemplate`은 대화목록을 프롬프트로 주입하고자 할 때 사용할 수 있다.\n",
    "메시지는 Tuple 형식으로 구성하며 (`role`, `message`)로 구성하여 리스트로 생성할 수 있다\n",
    "\n",
    "**role**\n",
    "- `\"system\"`: 시스템 설정 메시지로 전역설정과 관련 된 프롬프트이다\n",
    "- `\"human\"`: 사용자 입력 메시지 프롬프트이다.\n",
    "- `\"ai\"` : AI의 답변 메시지 프롬프트이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        # role, message\n",
    "        (\"system\", \"당신은 친절한 AI 어시스턴트입니다. 당신의 이름은 {name}입니다.\"),\n",
    "        (\"human\", \"반가워요!\"),\n",
    "        (\"ai\", \"안녕하세요! 무엇을 도와드릴까요?\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 춘식이는 카카오의 인기 캐릭터 중 하나입니다. 라이언의 친구로 등장하며, 귀여운 외모와 독특한 매력으로 많은 사랑을 받고 있습니다. 춘식이는 주로 재미있고 엉뚱한 행동을 하는 것으로 유명합니다. 더 궁금한 점이 있으면 말씀해 주세요!\n"
     ]
    }
   ],
   "source": [
    "chain = chat_prompt | llm\n",
    "\n",
    "# 이렇게 invoke 시 직접 호출하는 방법도 있고\n",
    "print(chain.invoke({\"name\": \"춘식\", \"user_input\": \"너는 춘식이에 대해 알아?\"}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "네, 춘식이는 카카오톡의 인기 캐릭터 중 하나입니다. 카카오프렌즈에 속한 캐릭터로, 귀여운 외모와 독특한 매력으로 많은 사람들에게 사랑받고 있어요. 일반적으로 춘식이는 곰으로 묘사되며, 종종 라이언과 함께 등장하기도 합니다. 더 궁금한 점 있으신가요?\n"
     ]
    }
   ],
   "source": [
    "# 이렇게 message를 생성하여 invoke 하여 직접 LLM 객체에 invoke 하는 방법도 있다\n",
    "message = chat_prompt.format_messages(name=\"춘식\", user_input=\"춘식이에 대해 알아?\")\n",
    "\n",
    "print(llm.invoke(message).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MessagePlaceholder\n",
    "\n",
    "LangChain은 렌더링할 메시지를 완전히 제어할 수 있는 `MessagePlaceholder`를 제공\n",
    "\n",
    "메시지 프롬프트 템플릿에 어떤 역할을 사용해야 할지 확실하지 않거나 서식 지정 중에 메시지 목록을 삽입하려는 경우 유용하게 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['conversation', 'word_count'], input_types={'conversation': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1219347c0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.'), additional_kwargs={}), MessagesPlaceholder(variable_name='conversation'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['word_count'], input_types={}, partial_variables={}, template='지금까지의 대화를 {word_count} 단어로 요약해줘.'), additional_kwargs={})])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"conversation\"),\n",
    "        (\"human\", \"지금까지의 대화를 {word_count} 단어로 요약해줘.\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'System: 당신은 요약 전문 AI 어시스턴트입니다. 당신의 임무는 주요 키워드로 대화를 요약하는 것입니다.\\nHuman: 안녕하세요! 저는 오늘 새로 입사한 춘식입니다. 만나서 반값습니다.\\nAI: 반가워요! 앞으로 잘 부탁 드립니다\\nHuman: 지금까지의 대화를 20 단어로 요약해줘.'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formatted_chat_prompt = chat_prompt.format(\n",
    "    word_count=20,\n",
    "    conversation=[\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 춘식입니다. 만나서 반값습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다\"),\n",
    "    ],\n",
    ")\n",
    "formatted_chat_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chain 생성\n",
    "chain = chat_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'새로 입사한 춘식, 반가움과 인사 나누는 대화.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\n",
    "    {\n",
    "        \"word_count\": 10,\n",
    "        \"conversation\": [\n",
    "        (\"human\", \"안녕하세요! 저는 오늘 새로 입사한 춘식입니다. 만나서 반값습니다.\"),\n",
    "        (\"ai\", \"반가워요! 앞으로 잘 부탁 드립니다\"),\n",
    "        ]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-kr-DBzZmRz6-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
